{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMHd6BiSlzEQ6LcQIacjECG",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jpbeaud/dbscan/blob/main/client.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_ygxaCdL7hTc"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "xM6LEC2Z58Pm",
        "outputId": "0649bb38-85d0-4c6f-98a9-be7042e94b7f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Début à 1730320763.1858473\n",
            "fichier DH2 format :\n",
            "   code_dept_naiss  code_lim_jur  code_pays_naiss  code_pays_nat_1  \\\n",
            "0             5253            48             7082             7082   \n",
            "1             5351            48             7082             7082   \n",
            "2             5354            48             7082             7082   \n",
            "3             5253            48             7082             7082   \n",
            "4             5056            48             7082             7082   \n",
            "\n",
            "   code_sit_familiale               intitule_lieu_naissance  \n",
            "0                4850                        79827669657883  \n",
            "1                4850  867376766573786983327665327485726976  \n",
            "2                4849                    726978786966797884  \n",
            "3                4849                        79827669657883  \n",
            "4                4850                      7465788673767669  \n",
            "fichier SIO format :\n",
            "   cod_postal_naiss  cod_aiguil_vie  country_naiss  nationality  \\\n",
            "0        5253323232              48         703232       703232   \n",
            "1        5351323232              48         703232       703232   \n",
            "2        5354323232              48         703232       703232   \n",
            "3        5253323232              48         703232       703232   \n",
            "4        5056323232              48         703232       703232   \n",
            "\n",
            "   nationality.1  marital_status  marital_status.1  \\\n",
            "0         703232              77                77   \n",
            "1         703232              77                77   \n",
            "2         703232              67                67   \n",
            "3         703232              67                67   \n",
            "4         703232              77                77   \n",
            "\n",
            "                                  nom_localite_naiss  \n",
            "0  7982766965788332323232323232323232323232323232...  \n",
            "1  8673767665737869833276653274857269763232323232...  \n",
            "2  7269787869667978843232323232323232323232323232...  \n",
            "3  7982766965788332323232323232323232323232323232...  \n",
            "4  7465788673767669323232323232323232323232323232...  \n",
            "fichier DH2 après scaler :\n",
            "[[-0.10894074 -0.04811807  0.34801554  0.12129307 -0.17764285 -0.00319405]\n",
            " [-0.10772797 -0.04811807  0.34801554  0.12129307 -0.17764285 -0.00319405]\n",
            " [-0.10769084 -0.04811807  0.34801554  0.12129307 -0.18411702 -0.00319405]\n",
            " [-0.10894074 -0.04811807  0.34801554  0.12129307 -0.18411702 -0.00319405]\n",
            " [-0.11137867 -0.04811807  0.34801554  0.12129307 -0.17764285 -0.00319405]]\n",
            "Estimated number of clusters DH: 1800\n",
            "Estimated number of noise points DH: 0\n",
            "fichier SIO après scaler :\n",
            "[[ 0.99524004 -0.13624662  0.34734841  0.13574068  0.43858857  0.63492088\n",
            "   0.63447928 -0.00316229]\n",
            " [ 1.03176323 -0.13624662  0.34734841  0.13574068  0.43858857  0.63492088\n",
            "   0.63447928 -0.00316229]\n",
            " [ 1.03288129 -0.13624662  0.34734841  0.13574068  0.43858857 -1.13808606\n",
            "  -1.13277895 -0.00316229]\n",
            " [ 0.99524004 -0.13624662  0.34734841  0.13574068  0.43858857 -1.13808606\n",
            "  -1.13277895 -0.00316229]\n",
            " [ 0.92182096 -0.13624662  0.34734841  0.13574068  0.43858857  0.63492088\n",
            "   0.63447928 -0.00316229]]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-7646904eb346>\u001b[0m in \u001b[0;36m<cell line: 108>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m \u001b[0;31m# Y = Y.apply(pd.to_numeric)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m \u001b[0mdb2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDBSCAN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.00000000000001\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_samples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmin_groupe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0mlabels_SIO\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdb2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabels_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1471\u001b[0m                 )\n\u001b[1;32m   1472\u001b[0m             ):\n\u001b[0;32m-> 1473\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfit_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1474\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1475\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_dbscan.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    420\u001b[0m         \u001b[0mneighbors_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    421\u001b[0m         \u001b[0;31m# This has worst case O(n^2) memory complexity\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 422\u001b[0;31m         \u001b[0mneighborhoods\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mneighbors_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mradius_neighbors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_distance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    423\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    424\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msample_weight\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/neighbors/_base.py\u001b[0m in \u001b[0;36mradius_neighbors\u001b[0;34m(self, X, radius, return_distance, sort_results)\u001b[0m\n\u001b[1;32m   1258\u001b[0m             \u001b[0mn_jobs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meffective_n_jobs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1259\u001b[0m             \u001b[0mdelayed_query\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdelayed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_tree_query_radius_parallel_helper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1260\u001b[0;31m             chunked_results = Parallel(n_jobs, prefer=\"threads\")(\n\u001b[0m\u001b[1;32m   1261\u001b[0m                 delayed_query(\n\u001b[1;32m   1262\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tree\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mradius\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_distance\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msort_results\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msort_results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mdelayed_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m         )\n\u001b[0;32m---> 74\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterable_with_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1916\u001b[0m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_sequential_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1917\u001b[0m             \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1918\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturn_generator\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1919\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1920\u001b[0m         \u001b[0;31m# Let's create an ID that uniquely identifies the current call. If the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_get_sequential_output\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1845\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_dispatched_batches\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1846\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_dispatched_tasks\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1847\u001b[0;31m                 \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1848\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_completed_tasks\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1849\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_progress\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    134\u001b[0m             \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mconfig_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 136\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    137\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/neighbors/_base.py\u001b[0m in \u001b[0;36m_tree_query_radius_parallel_helper\u001b[0;34m(tree, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1037\u001b[0m     \u001b[0mcloudpickle\u001b[0m \u001b[0munder\u001b[0m \u001b[0mPyPy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m     \"\"\"\n\u001b[0;32m-> 1039\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquery_radius\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import time\n",
        "\n",
        "def string_to_number(s):\n",
        "  return int(''.join(str(ord(char)) for char in s))\n",
        "\n",
        "\n",
        "\n",
        "chemin = \"/content/sample_data/\"\n",
        "debut = time.time()\n",
        "print(\"Début à\", debut)\n",
        "\n",
        "\n",
        "\n",
        "fichier_DH = pd.read_csv(chemin+\"extrac_DH.csv\", sep=\",\", dtype=str,skipinitialspace=True)\n",
        "\n",
        "fichier_DH = fichier_DH.replace(\"\", np.nan)\n",
        "fichier_DH = fichier_DH.fillna(0)\n",
        "\n",
        "fichier_DH = fichier_DH.astype(str)\n",
        "col_ref = ['id_personne']\n",
        "references_DH = fichier_DH[col_ref]\n",
        "\n",
        "\n",
        "\n",
        "fichier_DH.sort_values(by='id_personne')\n",
        "\n",
        "fichier_DH2 = fichier_DH\n",
        "fichier_DH2 = fichier_DH2.drop('id_personne', axis='columns')\n",
        "\n",
        "fichier_DH2= fichier_DH2.astype(str)\n",
        "fichier_DH2 = fichier_DH2.map(string_to_number)\n",
        "print (\"fichier DH2 format :\")\n",
        "print(fichier_DH2.head())\n",
        "\n",
        "\n",
        "#fichier_DH.set_index('id_personne', inplace=True) # inplace=True --> on ne crée pas un nouveau DF\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "fichier_SIO = pd.read_csv(chemin+\"extrac_SIO.csv\", sep=\",\", dtype=str,skipinitialspace=True)\n",
        "col_ref = ['client_reference']\n",
        "\n",
        "references_SIO= fichier_SIO[col_ref]\n",
        "ref_cli = references_SIO.to_numpy()\n",
        "\n",
        "fichier_SIO = fichier_SIO.replace(\"\", np.nan)\n",
        "fichier_SIO = fichier_SIO.fillna(0)\n",
        "\n",
        "\n",
        "\n",
        "fichier_SIO.sort_values(by='client_reference')\n",
        "fichier_SIO = fichier_SIO.astype(str)\n",
        "fichier_SIO = fichier_SIO.map(string_to_number)\n",
        "\n",
        "\n",
        "fichier_SIO = fichier_SIO.drop('client_reference',axis='columns')\n",
        "print (\"fichier SIO format :\")\n",
        "print(fichier_SIO.head())\n",
        "# X = fichier_DH.to_numpy()\n",
        "X = fichier_DH2\n",
        "#X.set_index('id_personne', inplace=True) # inplace=True --> on ne crée pas un nouveau DF\n",
        "\n",
        "# print(X.dtype)\n",
        "X = X.apply(pd.to_numeric)\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "# pltcatter(X[:, 3], X[:, 4])\n",
        "\n",
        "\n",
        "#plt.scatter(x=\"pcs\" , y=\"cosop\", c = 'r', data=X)\n",
        "#plt.show()\n",
        "\n",
        "from sklearn.datasets import make_blobs\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# création du jeu de test\n",
        "\n",
        "X = StandardScaler().fit_transform(X)\n",
        "print (\"fichier DH2 après scaler :\")\n",
        "print(X[:5])\n",
        "\n",
        "from sklearn import metrics\n",
        "from sklearn.cluster import DBSCAN\n",
        "from sklearn.cluster import OPTICS\n",
        "min_groupe = 1\n",
        "db = DBSCAN(eps=0.000000000000001,min_samples=min_groupe).fit(X)\n",
        "labels_DH = db.labels_\n",
        "\n",
        "n_clusters_ = len(set(labels_DH)) - (1 if -1 in labels_DH else 0)\n",
        "n_noise_ = list(labels_DH).count(-1)\n",
        "\n",
        "print(\"Estimated number of clusters DH: %d\" % n_clusters_)\n",
        "print(\"Estimated number of noise points DH: %d\" % n_noise_)\n",
        "\n",
        "\n",
        "Y = fichier_SIO\n",
        "\n",
        "\n",
        "Y = StandardScaler().fit_transform(Y)\n",
        "print (\"fichier SIO après scaler :\")\n",
        "print(Y[:5])\n",
        "\n",
        "\n",
        "# Y = Y.apply(pd.to_numeric)\n",
        "db2 = DBSCAN(eps=0.00000000000001, min_samples=min_groupe).fit(Y)\n",
        "labels_SIO = db2.labels_\n",
        "\n",
        "\n",
        "\n",
        "n_clusters_ = len(set(labels_SIO)) - (1 if -1 in labels_SIO else 0)\n",
        "n_noise_ = list(labels_SIO).count(-1)\n",
        "\n",
        "print(\"Estimated number of clusters SIO: %d\" % n_clusters_)\n",
        "print(\"Estimated number of noise points SIO: %d\" % n_noise_)\n",
        "print(\"____________Résumé____________\")\n",
        "difference = labels_DH - labels_SIO\n",
        "print(\"Données en écarts = \", difference)\n",
        "print(labels_DH)\n",
        "print(labels_SIO)\n",
        "n_DH = len(labels_DH)\n",
        "n_SIO=len(labels_SIO)\n",
        "n_dif = len(difference)\n",
        "print(\"Longueur dif = \", n_dif)\n",
        "fin = False\n",
        "i=-1\n",
        "\n",
        "nb_ko = 0\n",
        "\n",
        "# Créer un tableau vide avec une dimension initiale\n",
        "empty_array = np.empty((0, 3))  # Par exemple, un tableau vide avec 3 colonnes\n",
        "\n",
        "# Données à ajouter\n",
        "data_to_add = [\n",
        "    [1, 2, 3],\n",
        "    [4, 5, 6],\n",
        "    [7, 8, 9]\n",
        "]\n",
        "\n",
        "print(type(data_to_add))\n",
        "# Ajouter les données au tableau vide\n",
        "for row in data_to_add:\n",
        "    empty_array = np.vstack([empty_array, row])\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Test A"
      ],
      "metadata": {
        "id": "MFTe7fE4J7zm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "liste = []\n",
        "A = np.array((0,1000))\n",
        "for i in range(1):\n",
        "  liste = []\n",
        "  for j in range(1000):\n",
        "    liste.append(labels_DH[i] -labels_DH[j])\n",
        "  A = np.vstack([A,liste])\n",
        "\n",
        "\n",
        "print(A)\n",
        "\n",
        "RRR\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "while (i < n_dif - 1):\n",
        "    i = i + 1\n",
        "    if (difference[i] != 0):\n",
        "        print(\"i=\",i)\n",
        "        print(\"différence enregistrement \", str(i), \" DH=\", labels_DH[i], \"// SIO=\",labels_SIO[i], \"// ref=\", ref_cli[i,:])\n",
        "        #print(\"enr DH=\", fichier_DH.loc[i,:])\n",
        "        #print(\"enr SIO=\",fichier_SIO.loc[i,:])\n",
        "        nb_ko = nb_ko + 1\n",
        "        X = np.delete(X,i,0)\n",
        "        Y = np.delete(Y,i,0)\n",
        "        ref_cli = np.delete(ref_cli,i,0)\n",
        "        db = DBSCAN(eps=0.000000000000001,min_samples=min_groupe).fit(X)\n",
        "        labels_DH = db.labels_\n",
        "        db2 = DBSCAN(eps=0.00000000000001, min_samples=min_groupe).fit(Y)\n",
        "        labels_SIO = db2.labels_\n",
        "        difference = labels_DH - labels_SIO\n",
        "        n_dif = n_dif - 1\n",
        "\n",
        "\n",
        "lg = len(difference)\n",
        "#nb_ano = 0\n",
        "#for i in range(lg):\n",
        "#    if difference[i] !=0:\n",
        "#        nb_ano = nb_ano + 1\n",
        "print(\"ANOMALIES = \", nb_ko)\n",
        "#  3117773703\n",
        "\n",
        "fin_exec = time.time()\n",
        "temps = fin_exec - debut\n",
        "print(f'Temps d\\'exécution : {temps:.2}ms')"
      ],
      "metadata": {
        "id": "dULH6aiKJ-vC"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}