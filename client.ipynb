{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNLibWNF0Xd3CFzBF3OONDL",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jpbeaud/dbscan/blob/main/client.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_ygxaCdL7hTc"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xM6LEC2Z58Pm",
        "outputId": "8699f0ff-20c3-4890-96bb-64720d7699ce"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Début à 1730320905.332209\n",
            "fichier DH2 format :\n",
            "   code_dept_naiss  code_lim_jur  code_pays_naiss  code_pays_nat_1  \\\n",
            "0             5253            48             7082             7082   \n",
            "1             5351            48             7082             7082   \n",
            "2             5354            48             7082             7082   \n",
            "3             5253            48             7082             7082   \n",
            "4             5056            48             7082             7082   \n",
            "\n",
            "   code_sit_familiale               intitule_lieu_naissance  \n",
            "0                4850                        79827669657883  \n",
            "1                4850  867376766573786983327665327485726976  \n",
            "2                4849                    726978786966797884  \n",
            "3                4849                        79827669657883  \n",
            "4                4850                      7465788673767669  \n",
            "fichier SIO format :\n",
            "   cod_postal_naiss  cod_aiguil_vie  country_naiss  nationality  \\\n",
            "0        5253323232              48         703232       703232   \n",
            "1        5351323232              48         703232       703232   \n",
            "2        5354323232              48         703232       703232   \n",
            "3        5253323232              48         703232       703232   \n",
            "4        5056323232              48         703232       703232   \n",
            "\n",
            "   nationality.1  marital_status  marital_status.1  \\\n",
            "0         703232              77                77   \n",
            "1         703232              77                77   \n",
            "2         703232              67                67   \n",
            "3         703232              67                67   \n",
            "4         703232              77                77   \n",
            "\n",
            "                                  nom_localite_naiss  \n",
            "0  7982766965788332323232323232323232323232323232...  \n",
            "1  8673767665737869833276653274857269763232323232...  \n",
            "2  7269787869667978843232323232323232323232323232...  \n",
            "3  7982766965788332323232323232323232323232323232...  \n",
            "4  7465788673767669323232323232323232323232323232...  \n",
            "fichier DH2 après scaler :\n",
            "[[-0.10894074 -0.04811807  0.34801554  0.12129307 -0.17764285 -0.00319405]\n",
            " [-0.10772797 -0.04811807  0.34801554  0.12129307 -0.17764285 -0.00319405]\n",
            " [-0.10769084 -0.04811807  0.34801554  0.12129307 -0.18411702 -0.00319405]\n",
            " [-0.10894074 -0.04811807  0.34801554  0.12129307 -0.18411702 -0.00319405]\n",
            " [-0.11137867 -0.04811807  0.34801554  0.12129307 -0.17764285 -0.00319405]]\n",
            "Estimated number of clusters DH: 1800\n",
            "Estimated number of noise points DH: 0\n",
            "fichier SIO après scaler :\n",
            "[[ 0.99524004 -0.13624662  0.34734841  0.13574068  0.43858857  0.63492088\n",
            "   0.63447928 -0.00316229]\n",
            " [ 1.03176323 -0.13624662  0.34734841  0.13574068  0.43858857  0.63492088\n",
            "   0.63447928 -0.00316229]\n",
            " [ 1.03288129 -0.13624662  0.34734841  0.13574068  0.43858857 -1.13808606\n",
            "  -1.13277895 -0.00316229]\n",
            " [ 0.99524004 -0.13624662  0.34734841  0.13574068  0.43858857 -1.13808606\n",
            "  -1.13277895 -0.00316229]\n",
            " [ 0.92182096 -0.13624662  0.34734841  0.13574068  0.43858857  0.63492088\n",
            "   0.63447928 -0.00316229]]\n",
            "Estimated number of clusters SIO: 12205\n",
            "Estimated number of noise points SIO: 0\n",
            "____________Résumé____________\n",
            "Données en écarts =  [     0      0      0 ...    -21  -1399 -11508]\n",
            "[  0   1   2 ...   7 459 696]\n",
            "[    0     1     2 ...    28  1858 12204]\n",
            "Longueur dif =  100000\n",
            "<class 'list'>\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import time\n",
        "\n",
        "def string_to_number(s):\n",
        "  return int(''.join(str(ord(char)) for char in s))\n",
        "\n",
        "\n",
        "\n",
        "chemin = \"/content/sample_data/\"\n",
        "debut = time.time()\n",
        "print(\"Début à\", debut)\n",
        "\n",
        "\n",
        "\n",
        "fichier_DH = pd.read_csv(chemin+\"extrac_DH.csv\", sep=\",\", dtype=str,skipinitialspace=True)\n",
        "\n",
        "fichier_DH = fichier_DH.replace(\"\", np.nan)\n",
        "fichier_DH = fichier_DH.fillna(0)\n",
        "\n",
        "fichier_DH = fichier_DH.astype(str)\n",
        "col_ref = ['id_personne']\n",
        "references_DH = fichier_DH[col_ref]\n",
        "\n",
        "\n",
        "\n",
        "fichier_DH.sort_values(by='id_personne')\n",
        "\n",
        "fichier_DH2 = fichier_DH\n",
        "fichier_DH2 = fichier_DH2.drop('id_personne', axis='columns')\n",
        "\n",
        "fichier_DH2= fichier_DH2.astype(str)\n",
        "fichier_DH2 = fichier_DH2.map(string_to_number)\n",
        "print (\"fichier DH2 format :\")\n",
        "print(fichier_DH2.head())\n",
        "\n",
        "\n",
        "#fichier_DH.set_index('id_personne', inplace=True) # inplace=True --> on ne crée pas un nouveau DF\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "fichier_SIO = pd.read_csv(chemin+\"extrac_SIO.csv\", sep=\",\", dtype=str,skipinitialspace=True)\n",
        "col_ref = ['client_reference']\n",
        "\n",
        "references_SIO= fichier_SIO[col_ref]\n",
        "ref_cli = references_SIO.to_numpy()\n",
        "\n",
        "fichier_SIO = fichier_SIO.replace(\"\", np.nan)\n",
        "fichier_SIO = fichier_SIO.fillna(0)\n",
        "\n",
        "\n",
        "\n",
        "fichier_SIO.sort_values(by='client_reference')\n",
        "fichier_SIO = fichier_SIO.astype(str)\n",
        "fichier_SIO = fichier_SIO.map(string_to_number)\n",
        "\n",
        "\n",
        "fichier_SIO = fichier_SIO.drop('client_reference',axis='columns')\n",
        "print (\"fichier SIO format :\")\n",
        "print(fichier_SIO.head())\n",
        "# X = fichier_DH.to_numpy()\n",
        "X = fichier_DH2\n",
        "#X.set_index('id_personne', inplace=True) # inplace=True --> on ne crée pas un nouveau DF\n",
        "\n",
        "# print(X.dtype)\n",
        "X = X.apply(pd.to_numeric)\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "# pltcatter(X[:, 3], X[:, 4])\n",
        "\n",
        "\n",
        "#plt.scatter(x=\"pcs\" , y=\"cosop\", c = 'r', data=X)\n",
        "#plt.show()\n",
        "\n",
        "from sklearn.datasets import make_blobs\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# création du jeu de test\n",
        "\n",
        "X = StandardScaler().fit_transform(X)\n",
        "print (\"fichier DH2 après scaler :\")\n",
        "print(X[:5])\n",
        "\n",
        "from sklearn import metrics\n",
        "from sklearn.cluster import DBSCAN\n",
        "from sklearn.cluster import OPTICS\n",
        "min_groupe = 1\n",
        "db = DBSCAN(eps=0.000000000000001,min_samples=min_groupe).fit(X)\n",
        "labels_DH = db.labels_\n",
        "\n",
        "n_clusters_ = len(set(labels_DH)) - (1 if -1 in labels_DH else 0)\n",
        "n_noise_ = list(labels_DH).count(-1)\n",
        "\n",
        "print(\"Estimated number of clusters DH: %d\" % n_clusters_)\n",
        "print(\"Estimated number of noise points DH: %d\" % n_noise_)\n",
        "\n",
        "\n",
        "Y = fichier_SIO\n",
        "\n",
        "\n",
        "Y = StandardScaler().fit_transform(Y)\n",
        "print (\"fichier SIO après scaler :\")\n",
        "print(Y[:5])\n",
        "\n",
        "\n",
        "# Y = Y.apply(pd.to_numeric)\n",
        "db2 = DBSCAN(eps=0.00000000000001, min_samples=min_groupe).fit(Y)\n",
        "labels_SIO = db2.labels_\n",
        "\n",
        "\n",
        "\n",
        "n_clusters_ = len(set(labels_SIO)) - (1 if -1 in labels_SIO else 0)\n",
        "n_noise_ = list(labels_SIO).count(-1)\n",
        "\n",
        "print(\"Estimated number of clusters SIO: %d\" % n_clusters_)\n",
        "print(\"Estimated number of noise points SIO: %d\" % n_noise_)\n",
        "print(\"____________Résumé____________\")\n",
        "difference = labels_DH - labels_SIO\n",
        "print(\"Données en écarts = \", difference)\n",
        "print(labels_DH)\n",
        "print(labels_SIO)\n",
        "n_DH = len(labels_DH)\n",
        "n_SIO=len(labels_SIO)\n",
        "n_dif = len(difference)\n",
        "print(\"Longueur dif = \", n_dif)\n",
        "fin = False\n",
        "i=-1\n",
        "\n",
        "nb_ko = 0\n",
        "\n",
        "# Créer un tableau vide avec une dimension initiale\n",
        "empty_array = np.empty((0, 3))  # Par exemple, un tableau vide avec 3 colonnes\n",
        "\n",
        "# Données à ajouter\n",
        "data_to_add = [\n",
        "    [1, 2, 3],\n",
        "    [4, 5, 6],\n",
        "    [7, 8, 9]\n",
        "]\n",
        "\n",
        "print(type(data_to_add))\n",
        "# Ajouter les données au tableau vide\n",
        "for row in data_to_add:\n",
        "    empty_array = np.vstack([empty_array, row])\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Test A"
      ],
      "metadata": {
        "id": "MFTe7fE4J7zm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Deux tableaux à une dimension\n",
        "array1 = np.array([1, 2, 3])\n",
        "array2 = np.array([4, 5, 6]) # Empiler verticalement\n",
        "result = np.vstack((array1, array2))\n",
        "print(result)\n",
        "print(array1.shape)\n",
        "\n",
        "print(result.shape)\n",
        "\n",
        "\n",
        "liste = []\n",
        "A = np.array((0,1000), dtype=int)\n",
        "print(A.shape)\n",
        "for i in range(1):\n",
        "  liste = []\n",
        "  for j in range(1000):\n",
        "    liste.append(labels_DH[i] -labels_DH[j])\n",
        "  A = np.vstack([A,np.array(liste).reshape(1, -1)])\n",
        "\n",
        "\n",
        "print(A)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 471
        },
        "id": "dULH6aiKJ-vC",
        "outputId": "c504e197-2be5-4d14-87c6-dfb2c5a57464"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1 2 3]\n",
            " [4 5 6]]\n",
            "(3,)\n",
            "(2, 3)\n",
            "(2,)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "all the input array dimensions except for the concatenation axis must match exactly, but along dimension 1, the array at index 0 has size 2 and the array at index 1 has size 1000",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-dcc991951bbc>\u001b[0m in \u001b[0;36m<cell line: 14>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0mliste\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels_DH\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mlabels_DH\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m   \u001b[0mA\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mA\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mliste\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/numpy/core/shape_base.py\u001b[0m in \u001b[0;36mvstack\u001b[0;34m(tup, dtype, casting)\u001b[0m\n\u001b[1;32m    287\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m         \u001b[0marrs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0marrs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 289\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_nx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcasting\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcasting\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    290\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    291\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: all the input array dimensions except for the concatenation axis must match exactly, but along dimension 1, the array at index 0 has size 2 and the array at index 1 has size 1000"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Fin"
      ],
      "metadata": {
        "id": "H1RmNduDM0VY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "RRR\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "while (i < n_dif - 1):\n",
        "    i = i + 1\n",
        "    if (difference[i] != 0):\n",
        "        print(\"i=\",i)\n",
        "        print(\"différence enregistrement \", str(i), \" DH=\", labels_DH[i], \"// SIO=\",labels_SIO[i], \"// ref=\", ref_cli[i,:])\n",
        "        #print(\"enr DH=\", fichier_DH.loc[i,:])\n",
        "        #print(\"enr SIO=\",fichier_SIO.loc[i,:])\n",
        "        nb_ko = nb_ko + 1\n",
        "        X = np.delete(X,i,0)\n",
        "        Y = np.delete(Y,i,0)\n",
        "        ref_cli = np.delete(ref_cli,i,0)\n",
        "        db = DBSCAN(eps=0.000000000000001,min_samples=min_groupe).fit(X)\n",
        "        labels_DH = db.labels_\n",
        "        db2 = DBSCAN(eps=0.00000000000001, min_samples=min_groupe).fit(Y)\n",
        "        labels_SIO = db2.labels_\n",
        "        difference = labels_DH - labels_SIO\n",
        "        n_dif = n_dif - 1\n",
        "\n",
        "\n",
        "lg = len(difference)\n",
        "#nb_ano = 0\n",
        "#for i in range(lg):\n",
        "#    if difference[i] !=0:\n",
        "#        nb_ano = nb_ano + 1\n",
        "print(\"ANOMALIES = \", nb_ko)\n",
        "#  3117773703\n",
        "\n",
        "fin_exec = time.time()\n",
        "temps = fin_exec - debut\n",
        "print(f'Temps d\\'exécution : {temps:.2}ms')"
      ],
      "metadata": {
        "id": "ryYCroBZM2eB"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}